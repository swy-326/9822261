{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trabalho_IA_def.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "aCiSzAP-lTbX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffv98zYiL897",
        "outputId": "fd89732d-b7c3-4668-8b5e-6afef501f0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/USP/2022_1ยบ/ACH2016 IA/dados/DADOS/')\n",
        "\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "vUv2gDfLkDvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "# https://download.inep.gov.br/microdados/microdados_enem_2020.zip\n",
        "\n",
        "df = pd.read_csv('MICRODADOS_ENEM_2020.csv',encoding='ISO-8859-1', sep=';', dtype=str)[['TP_FAIXA_ETARIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO', 'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022', 'Q023', 'Q024', 'Q025', 'TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH', 'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT', 'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC', 'TX_GABARITO_MT']]\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "BttnRWRlGcux"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adapt dataset"
      ],
      "metadata": {
        "id": "pNEwuGjhkHpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular quantidade de acertos\n",
        "def calcular(a,b):\n",
        "    return sum (a[i] == b[i] for i in range(len(a)))\n",
        "\n",
        "df['CN_ACERTOS'] = df.apply(lambda x: calcular(x['TX_RESPOSTAS_CN'], x['TX_GABARITO_CN']), axis=1)\n",
        "df['CH_ACERTOS'] = df.apply(lambda x: calcular(x['TX_RESPOSTAS_CH'], x['TX_GABARITO_CH']), axis=1)\n",
        "df['LC_ACERTOS'] = df.apply(lambda x: calcular(x['TX_RESPOSTAS_LC'], x['TX_GABARITO_LC']), axis=1)\n",
        "df['MT_ACERTOS'] = df.apply(lambda x: calcular(x['TX_RESPOSTAS_MT'], x['TX_GABARITO_MT']), axis=1)\n",
        "df.drop(columns=['TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH', 'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT', 'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC', 'TX_GABARITO_MT'], inplace=True)\n",
        "\n",
        "\n",
        "# Calcular quantidade total de acertos\n",
        "df['Total_acertos'] = df.apply(lambda x: x['CN_ACERTOS']+x['CH_ACERTOS']+x['LC_ACERTOS']+x['MT_ACERTOS'], axis=1)\n",
        "df['Total_acertos_cat'] = df.apply(lambda x: x['Total_acertos'] // 10, axis=1)\n",
        "\n",
        "\n",
        "df['TP_SEXO'] = df['TP_SEXO'].map({'F': 1, 'M': 0})\n",
        "\n",
        "df.to_csv('dados-def.csv', encoding='ISO-8859-1', sep=';', index=False)"
      ],
      "metadata": {
        "id": "5AWWKhuVkKC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dados-def.csv',encoding='ISO-8859-1', sep=';', dtype=str)\n",
        "\n",
        "# acho q n pode fazer assim\n",
        "questoes = ['Q001', 'Q002', 'Q003', 'Q004', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022', 'Q023', 'Q024', 'Q025']\n",
        "for qst in questoes:\n",
        "    print(qst)\n",
        "    df[qst] = df[qst].map({'A': 1,  'B': 2,  'C': 3,  'D': 4,  'E': 5,  'F': 6,  'G': 7,  'H': 8,  'I': 9,  'J': 10,  'K': 11,  'L': 12,  'M': 13,  'N': 14,  'O': 15,  'P': 16,  'Q': 17})\n",
        "\n",
        "print(df)\n",
        "\n",
        "\n",
        "# Precisa normalizar ?\n",
        "# Dividir coluna numerica e categorica"
      ],
      "metadata": {
        "id": "FkXTMnvtWAPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train, Test"
      ],
      "metadata": {
        "id": "LsBB6Aj8kVlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.model_selection import KFold\n",
        "\n",
        "df = df.iloc[:5000] # so para o train n ser demorado\n",
        "\n",
        "y = df['Total_acertos_cat']\n",
        "features = ['TP_FAIXA_ETARIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO', 'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022', 'Q023', 'Q024', 'Q025', 'Total_acertos_cat']\n",
        "X = df[features]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "p2Uza-MnRY39"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def report(tam, y_test, y_pred):\n",
        "    print(\" (\"+str(tam).ljust(2, ' ')+\") \",end='')\n",
        "    p,r,f,_none = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "    print('  P =',\"{:2.2f}\".format(p).replace(\".\",\",\"),end='')\n",
        "    print('  R =',\"{:2.2f}\".format(r).replace(\".\",\",\"),end='')\n",
        "    print('  F =',\"{:2.2f}\".format(f).replace(\".\",\",\"))\n",
        "\n",
        "\n",
        "# Train\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Test\n",
        "y_pred = neigh.predict(X_test)\n",
        "report(X_test.shape[1], y_test, y_pred)"
      ],
      "metadata": {
        "id": "onv23EB3TwW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}